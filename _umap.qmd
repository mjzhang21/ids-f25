## Uniform Manifold Approximation and Projection                               |

This section was prepared by Mark Zhang, an undergraduate at UCONN.

+ Don’t forget to introduce yourself if there is no moderator.
+ Highlight your research questions and results, not code.
+ Give an outline, carry it out, and summarize.
+ Use your own examples to reduce the risk of plagiarism.

+ Pay attention to the sectioning levels.
+ Cite references with their bib key.
+ In examples, maximize usage of data set that the class is familiar with.
+ Could use datasets in Python packages or downloadable on the fly.
+ Test your section by `quarto render <filename.qmd>`.


### Introduction

Uniform Manifold Approximation and Projection (UMAP) was introduced by 
Leland McInnes, John Healy, and James Melville in 2018
[@mcinnes2020umapuniformmanifoldapproximation]. UMAP is a powerful 
dimensionality reduction technique designed to visualize high-dimensional 
data in a low-dimensional space, such as 2D or 3D. Unlike linear methods
like PCA, UMAP captures nonlinear structures, preserving local clusters 
while also maintaining the overall global patterns of the data. UMAP is 
utilized forclustering, data visualization, and data exploration.


### Other Dimensionality Reduction Techniques

#### Principle Component Analysis (PCA)
- linear technique; projects data along directions of maximum variance
- Preserves global structure fairly well but may lose local neighborhood 
  details.
- good for visualization of 2-3 PCs but cannot capture nonlinear
  structures.


#### t-distributed Stochastic Neighbor Embedding (t-SNE)
- finds distances between pairs of points, maps onto t dist.
- nonlinear technique; preserves local structure very well.
- can distort global relationships
- often slower than UMAP for large datasets

### Algorithm Approach and Intuition
UMAP is a graph-based dimensionality reduction algorithm rooted in algebraic
topology. It represents data as a fuzzy graph and finds a low-dimensional
embedding that preserves both local neighborhoods and global structure.

#### Mathematical Foundations

1. Riemannian Manifold
UMAP assumes the data lies on a Riemannian manifold, 
a smoothly curved surface embedded in high-dimensional space.

1. Simplicial Sets
From algebraic topology, a simplex is the simplest geometric building 
block (a point, line, triangle, etc.), and a simplicial complex describes
how these pieces connect to form a space. Geometrically a k-simplex is a 
very simple way to build a k-dimensional object.

#### Learning the manifold structure
UMAP builds a graph as a discrete approximation of the manifold’s structure.
To aid in visualizing the concepts, I will show how they apply to a noisy
sin wave data set.
```{python}
#| fig-cap: "Test data set of a noisy sin wave"
#| echo: false
#| message: false
import matplotlib.pyplot as plt
import numpy as np
np.random.seed(3255)

# 25 points along sin waves
x = np.sort(np.random.rand(25) * 8)

y = np.sin(x)
xlim = (0, 8)
# generate random numbers from normal dist
noise = 0.1 * np.random.randn(len(x))
y = y + noise
fig, ax = plt.subplots(figsize=(10,6)) 
ax.scatter(x, y, color='blue')
ax.set_aspect('equal',adjustable='datalim')
ax.set_xlim(xlim)
plt.axis('off')
plt.show()
```

How do we represent this data as a manifold? UMAP uses the concept of simplicial
sets and topology and adapts them to fuzzy simplicial sets and metric space.


##### Finding nearest neighbors
For each point we find the nearest neighbors. This hyperparameter controls
how local or global we want our structure to be. A large amount of neighbors
represent the manifold more accurately as a whole and a smaller number would
capture fine details of the structure.
```{python}
#| fig-cap: "Fuzzy circles to 4th nearest neighbor"
#| echo: false
#| message: false
#| warning: false
import matplotlib.pyplot as plt
import numpy as np
from sklearn.neighbors import NearestNeighbors

np.random.seed(3255)

# 25 noisy sine points
x = np.sort(np.random.rand(25) * 8)
y = np.sin(x) + 0.1 * np.random.randn(len(x))
X = np.column_stack((x, y))

# Find 4 nearest neighbors for each point
k = 4
nbrs = NearestNeighbors(n_neighbors=k+1).fit(X)
distances, indices = nbrs.kneighbors(X)

# Plot base points
fig, ax = plt.subplots(figsize=(10,6))
ax.scatter(x, y, color='blue', zorder=3)

# Compute sigma = mean of neighbor distances (for fuzziness decay)
sigma = np.mean(distances[:, 1:])

# Draw fuzzy balls for each point (to its 4th neighbor)
for i, (xi, yi) in enumerate(X):
    for j in range(1, k+1):  # skip self (j=0)
        d = distances[i, j]
        w = np.exp(-d / sigma)  # fuzzy weight between 0 and 1
        circle = plt.Circle((xi, yi), d, color='blue', alpha=w * 0.15, lw=0)
        ax.add_patch(circle)

ax.set_aspect('equal', adjustable='datalim')
ax.set_xlim(xlim)
ax.axis('off')
plt.show()
```

##### Constructing a neighborhood graph

UMAP represents high-dimensional data as a fuzzy simplicial set, capturing the 
local connectivity of points. For each point, a fuzzy membership weight is 
assigned to its neighbors:

$$
w_{ij} = \exp\Bigg(-\frac{d_{ij} - \rho_i}{\sigma_i}\Bigg)
$$

where:

- $d_{ij}$ is the distance between points $i$ and $j$
- $\rho_i$ is the distance to the closest neighbor of $i$
- $\sigma_i$ is a local scaling factor. 

In other words, each point adjusts its influence based on the local density of
its neighborhood. Dense regions, where points are very close together, have
 smaller $\sigma_i$, which reduces the weight of individual connections.
 Sparse regions, with points farther apart, have larger $\sigma_i$.
, increasing the weight of each connection.


Since $w_{i \to j}$ and $w_{j \to i}$ can differ, UMAP combines them 
using a probabilistic union:

$$
w_{ij}^{(final)} = w_{i \to j} + w_{j \to i} - w_{i \to j} \cdot w_{j \to i}
$$

This produces a symmetric weight between 0 and 1 that preserves local 
topology, balances contributions across dense and sparse regions, and 
yields a uniform manifold representation.

#### Finding a low-dimensional representation
##### Minimum Distance


##### Minimizing the cost function (Cross-Entropy)


### Practical Example



### Conclusion



### Further Readings


